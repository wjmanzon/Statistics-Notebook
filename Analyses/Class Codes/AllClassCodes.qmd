---
title: "All Class Codes"
execute:
  keep-md: true
  df-print: paged
  warning: false
format:
  html:
    code-fold: false
    code-line-numbers: true
editor_options: 
  chunk_output_type: console
---

# Week 2 Day 1
```{r}
library(mosaic)
library(pander)
library(tidyverse)
library(car)
```

## Making Inference

### Define Inference

```{r}
# Define inference first in class and then with the group.
# Do not use the textbook when going over this. Use the script below as your guide.
```

### Hypothesis Testing


## Type I Error vs Type II Error – Examples (Flip flops vs medicine)

```{r}
# Type I error: False positive (rejecting a true null hypothesis)
# Type II error: False negative (failing to reject a false null hypothesis)

# Example:
# Imagine a scenario where you are testing the effectiveness of a new medicine.
# - Null hypothesis (H0): The medicine has no effect.
# - Type I error: You conclude that the medicine is effective when it actually isn't. 
#   This can lead to unnecessary side effects and costs.
# - Type II error: You conclude that the medicine is not effective when it actually is.
#   This means a useful treatment is rejected, possibly harming patients who need it.

# Another Example:
# Suppose you are testing if flip-flops are waterproof.
# - Null hypothesis (H0): Flip-flops are waterproof.
# - Type I error: You conclude that flip-flops are not waterproof when they actually are.
# - Type II error: You conclude that flip-flops are waterproof when they actually aren’t.
```

## Type I Error and Level of Significance

```{r}
# Type I error = Level of significance = 1 – level of confidence
# The significance level (alpha) represents the probability of making a Type I error.
# Example: If the confidence level is 95%, then the significance level (alpha) is 0.05.
# This means there is a 5% chance of rejecting a true null hypothesis.
```

## Type II Errors and Power

```{r}
# Power = 1 - Type II error rate
# The power of a test is the probability of correctly rejecting a false null hypothesis.
# A higher power means a lower probability of making a Type II error.
# Increasing sample size, effect size, or significance level can improve statistical power.
```

## Sufficient Evidence – Not Proof

```{r}
# Hypothesis testing does not provide absolute proof but rather sufficient statistical evidence.
# - A statistically significant result suggests that an effect exists, but it does not confirm it with certainty.
# - External factors, assumptions, and sample limitations must be considered.
# - Scientific conclusions should be drawn cautiously based on the strength of the evidence.
```

## P-value Calculation

```{r}
# P-value needs two things: a test statistic and a sampling distribution of the test statistic
# - The test statistic is calculated based on sample data (e.g., t-score, z-score, F-statistic).
# - The sampling distribution describes how the test statistic behaves under the null hypothesis.
# - The p-value measures how extreme the observed test statistic is, assuming the null hypothesis is true.
# - A small p-value suggests evidence against the null hypothesis, leading to potential rejection of H0.
```


### Peer Review Analysis

```{r}
# 1) Go to the Analysis Menu and open Good Example Analysis
# 2) Summary of Student Peer Reviews for the Good Example Analysis
# 3) Identify at least one student who you would like feedback from
# 4) Identify at least one student that you would NOT like to give you feedback on future assignments.
# 5) Find an example of Good Specific Feedback
# To practice, locate at least one student feedback where the feedback
# is specific enough that if it were given to the wrong student
# that student wouldn't find it useful, but the right student would find it useful.
# 6) With Peers, identify things you should avoid doing
# 7) With Peers, identify principles that would make for a good critique
```

### Data Exploration

```{r}
View(KidsFeet)
```

### Group 1 Analysis

```{r}
boxplot(length~sex, data=KidsFeet)
```

```{r}
KidsFeet %>% 
  group_by(sex) %>% 
  summarise(min = min(length), Q1=quantile(length, 0.25), median=median(length), Q3=quantile(length, 0.75),
            max=max(length))
```

```{r}
favstats(length~sex, data=KidsFeet)
```

### Group 2 Analysis

```{r}
barplot(table(KidsFeet$sex))
```

```{r}
table(KidsFeet$sex)
```

### Group 3 Analysis

```{r}
plot(length~width, data=KidsFeet)
```

```{r}
KidsFeet %>% 
  summarise(Correlation=cor(width, length))
```

### Notes

```{r}
# Add any notes to your Index file in the Statistics Notebook
```



# Week 2 Day 2

# Day 1

## A) Take a few moments to knit your index.rmd file
## B) Do the Good Graphics question in the quiz

```{r}
library(mosaic)
library(tidyverse)
```

```{r}
View(airquality)
# ?airquality
```

## Histograms (length)

```{r}
hist(airquality$Wind,main="La Guardia Airport from May to September, 1973", 
     xlab="Daily Average Wind Speeds (mph)",ylab="Frequency",col="steelblue",breaks = 22)
```

```{r}
ggplot(airquality,aes(x=Wind))+
  geom_histogram(fill="steelblue")+
  labs(title="La Guardia Airport from May to September, 1973",
       x="Daily Average Wind Speeds (mph)",
       y="Frequency")
```

## Go through the four questions below for Question 3

## Boxplots

```{r}
boxplot(Wind~Month,main="Wind by Month", xlab="Month",
     ylab="Wind",col=c("steelblue1", "steelblue2", "steelblue3","steelblue3",
                       "steelblue2"),data=airquality)
```

```{r}
ggplot(data=airquality,aes(y=Wind,x=Month,group=Month))+
  geom_boxplot(fill=c("steelblue1", "steelblue2", "steelblue3","steelblue3",
                      "steelblue2"))+
  labs(title = "Wind by Month",
       y="Wind",
       x="Month")
```

## Scatterplots

```{r}
plot(Ozone~Temp,data=airquality,main="Relationship Between Ozone and Temperature",
     xlab="Temp", ylab="Ozone",pch = 19, col="blue")
```

```{r}
ggplot(airquality,aes(x=Temp,y=Ozone))+
  geom_point(color="blue")+
  labs(title="Relationship Between Ozone and Temperature", 
       x="Temp", 
       y="Ozone")
```

## Go over the Stephanie analysis






# Week 3

```{r}
library(mosaic)
library(tidyverse)
library(pander)
```

## Day 1

### A) Quantitative vs Categorical Data - KidsFeet

```{r}
# One Quantitative Response Variable Y - length
summary(KidsFeet$length)
```

```{r}
# Quantitative Y | Categorical X (2 Groups) - length by sex
tapply(KidsFeet$length, KidsFeet$sex, summary)
```

```{r}
# Quantitative Y | Categorical X (3+ Groups) - Nothing in the data with 3+ groups
```

```{r}
# Quantitative Y | Multiple Categorical X - length by sex and biggerfoot
tapply(KidsFeet$length, list(KidsFeet$sex, KidsFeet$biggerfoot), summary)
```

```{r}
# Quantitative Y | Quantitative X - length and width
cor(KidsFeet$length, KidsFeet$width)
```

```{r}
# Quantitative Y | Multiple X  - length and width and sex
lm(length ~ width + sex, data = KidsFeet)
```

```{r}
# Binomial Y | Quantitative X - sex and length - opposite x and y 
glm(sex ~ length, data = KidsFeet, family = binomial)
```

```{r}
# Binomial Y | Multiple X - Don't worry about it
```

```{r}
# Categorical Y | Categorical X - biggerfoot and domhand
table(KidsFeet$biggerfoot, KidsFeet$domhand)
```

### B - Summary Statistics

```{r}
# group_by() - categorical
KidsFeet %>% 
  group_by(sex) %>% 
  summarise(mean_length = mean(length))
```

### C - Visualization

```{r}
# Histogram - quantitative
hist(KidsFeet$length, main="Histogram of Kids Feet Length", xlab="Length")
```

```{r}
# Boxplot - quantitative
boxplot(KidsFeet$length, main="Boxplot of Kids Feet Length", xlab="Length")
```

```{r}
# Dot plot - quantitative
stripchart(KidsFeet$length, method = "jitter", pch = 19, col = "blue", main = "Dot Plot of Kids Feet Length")
```

```{r}
# Scatterplot - quantitative
plot(KidsFeet$width, KidsFeet$length, main="Scatterplot of Length vs Width", xlab="Width", ylab="Length")
```

```{r}
# Bar plot - categorical
barplot(table(KidsFeet$sex), main="Barplot of Gender Count", col=c("blue","pink"))
```

### D - Answering Specific Questions

```{r}
# How many boys and how many girls are in the KidsFeet dataset?
table(KidsFeet$sex)
```

```{r}
barplot(table(KidsFeet$sex), col=c("blue", "pink"), main="Count of Boys and Girls")
```

```{r}
# What is the average length of feet in the KidsFeet dataset?
favstats(KidsFeet$length) %>% pander()
```

```{r}
boxplot(KidsFeet$length, main="Length of Kids Feet")
```

```{r}
# Do boys or girls have longer feet, on average?
favstats(length~sex, data=KidsFeet) %>% pander()
```

```{r}
boxplot(length~sex, data=KidsFeet, main="Comparing Length of Feet Across Gender", 
        xlab="Gender", ylab="Length of Foot", col=c("blue","pink"))
```

```{r}
# Are there certain months of the year associated with longer feet?
favstats(length~birthmonth, data=KidsFeet) %>% pander()
```

```{r}
boxplot(length~birthmonth, data=KidsFeet, col="navy",
        xlab = "Numerical Birth Month", ylab="Feet Length")
```

```{r}
# Is there a relationship between foot length and width?
cor(KidsFeet$length, KidsFeet$width)
```

```{r}
plot(length~width, data=KidsFeet, main="Relationship Between Length and Width of Kids Feet", 
     xlab="Width of Foot", ylab = "Length of Foot")
```

```{r}
# Is one gender more likely to be born in certain seasons?
Kids3 <- KidsFeet %>% 
  mutate(
    season = case_when(
      birthmonth %in% c(12,1,2) ~ "Winter",
      birthmonth %in% c(3,4,5) ~ "Spring",
      birthmonth %in% c(6,7,8) ~ "Summer",
      birthmonth %in% c(9,10,11) ~ "Fall"
    )
  )  
```

```{r}
pander(table(Kids3$season, KidsFeet$sex))
```

```{r}
barplot(table(Kids3$sex, Kids3$season), beside = TRUE,
        col = c("blue","pink"), legend.text=TRUE, 
        xlab="Season", ylab="Frequency", main="Count of Gender by Season")
```


# Week 4 Day 1
```{r setup, include=FALSE}
library(mosaic)
library(pander)
```

## Making Inference

### Define Inference

```{r}
# Define inference first in class and then with the group.
# Do not use the textbook when going over this. Use the script below as your guide.
```

### Hypothesis Testing

```{r}
# a. Type I error vs Type II error – Give an example (Flip flops vs medicine)
# Type I error: False positive (rejecting a true null hypothesis)
# Type II error: False negative (failing to reject a false null hypothesis)
```

```{r}
# b. Type I error = Level of significance = 1 – level of confidence
# Example: If confidence level is 95%, significance level is 0.05
```

```{r}
# c. Type II errors and Power
# Power = 1 - Type II error rate
```

```{r}
# d. Sufficient evidence – not proof
# Hypothesis testing does not prove anything; it only provides sufficient evidence to support/reject a hypothesis.
```

```{r}
# e. P-value needs two things: a test statistic and a sampling distribution of test statistic
```

### Parametric Distributions

```{r}
# Find the four parametric distributions (types of tests that are run in 221)
# 1. Normal distribution
# 2. t-distribution
# 3. Chi-square distribution
# 4. F-distribution
```

### Parametric vs Non-Parametric Methods

```{r}
# Parametric methods compared to non-parametric methods
# Non-parametric tests are still powerful and are likely more powerful than parametric tests 
# if the requirements for a parametric test are not met.
```

### Example of a t-Test

```{r}
# Conducting a one-sample t-test
t.test(KidsFeet$length, mu=25.1, alternative="two.sided", conf.level=0.95)
```

```{r}
# Ho: mu = 25.1, Ha: mu ≠ 25.1
# Level of significance = 0.05
# Test Statistic t = -1.7865, df = 38, p-value = 0.082
# p-value > alpha, therefore we fail to reject the Ho
# We have insufficient evidence to say that the mean is different than 25.1.
```

```{r}
pander(t.test(KidsFeet$length, mu=25.1, alternative="less", conf.level=0.95))
```

```{r}
# Ho: mu = 25.1, Ha: mu < 25.1
# Level of significance = 0.05
# Test Statistic t = -1.7865, df = 38, p-value = 0.041
# p-value < alpha, therefore we reject the Ho
# We have sufficient evidence to say that the mean is less than 25.1.
```

```{r}
# Note: Because of the Central Limit Theorem, we can assume the distribution
# of sample means is normal because we have a large sample size (n >= 30).
```

### Two-Sample t-Test

```{r}
t.test(length~sex, data=KidsFeet, mu=0, alternative="greater", conf.level=0.95)
```

```{r}
library(mosaic)
library(pander)
library(tidyverse)
library(car)
```

## Making Inference

### Define Inference

```{r}
# Define inference first in class and then with the group.
# Do not use the textbook when going over this. Use the script below as your guide.
```

### Hypothesis Testing

```{r}
# a. Type I error vs Type II error – Give an example (Flip flops vs medicine)
# Type I error: False positive (rejecting a true null hypothesis)
# Type II error: False negative (failing to reject a false null hypothesis)
```

```{r}
# b. Type I error = Level of significance = 1 – level of confidence
# Example: If confidence level is 95%, significance level is 0.05
```

```{r}
# c. Type II errors and Power
# Power = 1 - Type II error rate
```

```{r}
# d. Sufficient evidence – not proof
# Hypothesis testing does not prove anything; it only provides sufficient evidence to support/reject a hypothesis.
```

```{r}
# e. P-value needs two things: a test statistic and a sampling distribution of test statistic
```

### Parametric Distributions

```{r}
# Find the four parametric distributions (types of tests that are run in 221)
# 1. Normal distribution
# 2. t-distribution
# 3. Chi-square distribution
# 4. F-distribution
```

### Parametric vs Non-Parametric Methods

```{r}
# Parametric methods compared to non-parametric methods
# Non-parametric tests are still powerful and are likely more powerful than parametric tests 
# if the requirements for a parametric test are not met.
```

### Example of a One-Sample t-Test

```{r}
pander(t.test(KidsFeet$length, mu=28, alternative="two.sided", conf.level=0.95))
```

```{r}
# Ho: mu = 28, Ha: mu ≠ 28
# Level of significance = 0.05
# Test Statistic t = -15.532, df = 38, p-value < 2.2e-16
# p-value < alpha, therefore we reject the Ho
# We have sufficient evidence to say that the mean is different than 28.
```

### Example of a Paired t-Test

```{r}
KidsFeet3 <- KidsFeet %>% 
  mutate(width3 = 3*width, difference = length - width3) 
```

```{r}
t.test(KidsFeet3$length, KidsFeet3$width3, mu=0, paired=TRUE,
       alternative="two.sided", conf.level=0.95)
```

```{r}
# Ho: mu_d = 0, Ha: mu_d ≠ 0
# Level of significance = 0.05
# t = -11.529, df = 38, p-value = 5.668e-14
# p-value < alpha, therefore we reject the Ho
# We have sufficient evidence to say that there is a difference between width*3 and length.
```

### Example of an Independent Samples t-Test

```{r}
t.test(length~sex, mu=0, data=KidsFeet, alternative="two.sided", conf.level=0.95)
```

```{r}
# Ho: mu_boy = mu_girl, Ha: mu_boy ≠ mu_girl
# Level of significance = 0.05
# t = 1.9174, df = 36.275, p-value = 0.06308
# p-value > alpha, therefore we fail to reject the Ho
# We have insufficient evidence to say that the length is different between boys and girls.
```

### Checking Requirements

```{r}
# One Sample t-Test
qqPlot(KidsFeet$length)
```

```{r}
# Paired t-Test
qqPlot(KidsFeet3$length - KidsFeet3$width3)
```

```{r}
# Independent Samples t-Test
qqPlot(length~sex, data=KidsFeet)
```

### Graphics

```{r}
# One Sample t-Test
boxplot(KidsFeet$length)
ggplot(data=KidsFeet, aes(x=length)) + geom_boxplot(fill="blue")
```

```{r}
# Paired t-Test
boxplot(KidsFeet3$length - KidsFeet3$width3)
ggplot(data=KidsFeet3, aes(x=difference)) + geom_boxplot(fill="blue")
```

```{r}
# Independent Samples t-Test
boxplot(length~sex, data=KidsFeet)
ggplot(data=KidsFeet, aes(y=length, x=sex)) + geom_boxplot(fill=c("blue","pink"))
```

### Numerical Summaries

```{r}
# One Sample t-Test
pander(favstats(KidsFeet$length))
```

```{r}
# Paired t-Test
pander(favstats(KidsFeet3$length - KidsFeet3$width3))
```

```{r}
# Independent Samples t-Test
pander(favstats(length~sex, data=KidsFeet))
```






