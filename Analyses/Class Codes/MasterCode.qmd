---
title: "Intermediate Statistics Notes"
author: "Wilson Jr Manzon"
execute:
  keep-md: true
  df-print: paged
  warning: false
format:
  html:
    theme: cerulean
    toc: true
    toc-search: true
    code-fold: false
    code-line-numbers: true
---



# Week 2 Day 1
```{r}
library(mosaic)
library(pander)
library(tidyverse)
library(car)
```

## Making Inference
Inference is the process of using information from a sample to make a general statement about an entire population. It involves using data from a subset of a population to infer something about the larger group.

### Define Inference
```{r}
# Define inference first in class and then with the group.
# Do not use the textbook when going over this. Use the script below as your guide.
```

### Hypothesis Testing

### Type I vs. Type II Errors – Example: Flip Flops vs. Medicine

#### Type I Error (FALSE POSITIVE)
  - Rejecting a true null hypothesis.
  - It is the probability of rejecting the null hypothesis when you **should have accepted it**.
  - **Example:** A medical test incorrectly detects a disease in a healthy person.

#### Type II Error (FALSE NEGATIVE)
  - Failing to reject a false null hypothesis.
  - It is the probability of accepting the null hypothesis when you **should have rejected it**.
  - **Example:** A medical test fails to detect a disease in a sick person.

**In decision-making,**  
  - **Type I errors lead to UNNECESSARY ACTIONS.**  
  - **Type II errors result in MISSED DETECTIONS.**  

### Remembering Type I and II Errors:

#### Hypothesis Definitions:
  - **Null Hypothesis (H₀):** There is no fire.
  - **Alternative Hypothesis (H₁):** There is a fire.

#### Type I Error (FALSE POSITIVE) – "False Alarm"
  - You **reject** the null hypothesis when you **should have accepted it**.
  - **Example:** The fire alarm goes off, but there’s **no actual fire**.
  - **Think:** Overreaction—detecting something that isn’t actually there.

#### Type II Error (FALSE NEGATIVE) – "Missed Detection"
  - You **accept** the null hypothesis when you **should have rejected it**.
  - **Example:** You **miss** detecting a real fire because the alarm **didn’t go off**.
  - **Think:** Underreaction—failing to detect something that actually exists.


| **Decision**         | **Accept H₀ (No Fire)** | **Reject H₀ (Fire Alarm Goes Off)** |
|----------------------|------------------------|-------------------------------------|
| **H₀ is True (No Fire)**  | ✅ Correct Decision  | ❌ Type I Error (False Alarm)       |
| **H₀ is False (There is a Fire)** | ❌ Type II Error (Missed Detection) | ✅ Correct Decision |


### Type I Error and Significance Level

  - **Type I Error = Significance Level (α) = 1 – Confidence Level**
  - The significance level (α) is the probability of making a Type I error.
  - A **lower α** reduces the chance of rejecting a true null hypothesis.

#### Example:
  - A **95% confidence level** means a **0.05 significance level (α = 0.05)**.
  - This means there is a **5% chance of incorrectly rejecting a true null hypothesis**.

### Type II Errors and Power

  - **Type II error:** Probability of accepting the null hypothesis when you **should have rejected it**.
  - **Power of a test:** Probability of correctly rejecting a false null hypothesis.
  - **Power = 1 - Probability of a Type II error**.
  - A **higher power** means a **lower** chance of making a Type II error.
  - **Increasing sample size, effect size, or significance level** can improve power.

#### Example:
  - Suppose a new drug is being tested for effectiveness against a disease.
    - **H₀:** The drug has no effect.
    - **H₁:** The drug is effective.
  - A **Type II error** occurs if we conclude the drug is ineffective (**accept H₀**)  
    when it actually works (**H₁ is true**).
  - The **power** of the test is the probability of correctly detecting the drug's effectiveness.
  - If power is **80%**, it means there’s a **20% chance** of failing to detect a real effect (**Type II error**).

### Sufficient Evidence ≠ Proof

  - Hypothesis testing does **not** **prove** anything.
  - It only provides **sufficient evidence** to support or reject a hypothesis.

### P-Value Requires Two Components:

1. **A test statistic**
2. **The sampling distribution of the test statistic**

## P-value Calculation

## P-value Requirements

A **p-value** requires two components:

1. **Test Statistic** – A value computed from sample data, such as:
   - t-score
   - z-score
   - F-statistic

2. **Sampling Distribution of the Test Statistic** – Describes how the test statistic behaves under the null hypothesis.

### Interpretation:
  - The **p-value** measures how extreme the observed test statistic is, assuming the null hypothesis is true.
  - A **small p-value** suggests evidence against the null hypothesis, potentially leading to rejection of \( H_0 \).


### Data Exploration

```{r}
View(KidsFeet)
```

#### Group 1 Analysis

```{r}
boxplot(length~sex, data=KidsFeet)
```

```{r}
summary <- KidsFeet %>% 
  group_by(sex) %>% 
  summarise(min = min(length), 
            Q1=quantile(length, 0.25), 
            median=median(length), 
            Q3=quantile(length, 0.75),
            max=max(length))

summary
```

```{r}
summary <- favstats(length~sex, data=KidsFeet)

summary
```

#### Group 2 Analysis

```{r}
barplot(table(KidsFeet$sex))
```

```{r}
table(KidsFeet$sex)
```

#### Group 3 Analysis

```{r}
plot(length~width, data=KidsFeet)
```

```{r}
KidsFeet %>% 
  summarise(Correlation=cor(width, length))
```

---


# Week 2 Day 2

1) Take a few moments to knit your index.rmd file
2) Do the Good Graphics question in the quiz
3) Go over the Stephanie Analysis

```{r}
library(mosaic)
library(tidyverse)
```

```{r}
View(airquality)
# ?airquality
```

## Histograms (length)

```{r}
hist(airquality$Wind,main="La Guardia Airport from May to September, 1973", 
     xlab="Daily Average Wind Speeds (mph)",ylab="Frequency",col="steelblue",breaks = 22)
```

```{r}
ggplot(airquality,aes(x=Wind))+
  geom_histogram(fill="steelblue")+
  labs(title="La Guardia Airport from May to September, 1973",
       x="Daily Average Wind Speeds (mph)",
       y="Frequency")
```

## Go through the four questions below for Question 3

## Boxplots

```{r}
boxplot(Wind~Month,main="Wind by Month", xlab="Month",
     ylab="Wind",col=c("steelblue1", "steelblue2", "steelblue3","steelblue3",
                       "steelblue2"),data=airquality)
```

```{r}
ggplot(data=airquality,aes(y=Wind,x=Month,group=Month))+
  geom_boxplot(fill=c("steelblue1", "steelblue2", "steelblue3","steelblue3",
                      "steelblue2"))+
  labs(title = "Wind by Month",
       y="Wind",
       x="Month")
```

## Scatterplots

```{r}
plot(Ozone~Temp,data=airquality,main="Relationship Between Ozone and Temperature",
     xlab="Temp", ylab="Ozone",pch = 19, col="blue")
```

```{r}
ggplot(airquality,aes(x=Temp,y=Ozone))+
  geom_point(color="blue")+
  labs(title="Relationship Between Ozone and Temperature", 
       x="Temp", 
       y="Ozone")
```

---

# Week 3 Days 1 & 2

```{r}
library(mosaic)
library(tidyverse)
library(pander)
```

### A) Quantitative vs Categorical Data - KidsFeet

```{r}
# One Quantitative Response Variable Y - length
summary(KidsFeet$length) %>%
  pander()
```

```{r}
# Quantitative Y | Categorical X (2 Groups) - length by sex
tapply(KidsFeet$length, KidsFeet$sex, summary) %>%
  pander()
# NOTE: tapply() is a function used to apply a function to subsets of a vector, grouped by factors. It is particularly useful for summarizing data by categories
```

```{r}
# Quantitative Y | Categorical X (3+ Groups) - Nothing in the data with 3+ groups
```

```{r}
# Quantitative Y | Multiple Categorical X - length by sex and biggerfoot
tapply(KidsFeet$length, list(KidsFeet$sex, KidsFeet$biggerfoot), summary) %>%
  pander()
```

```{r}
# Quantitative Y | Quantitative X - length and width
cor(KidsFeet$length, KidsFeet$width) %>%
  pander()

# The function cor(KidsFeet$length, KidsFeet$width) in R calculates the Pearson correlation 
# coefficient between the length and width columns of the KidsFeet dataset, measuring the 
# strength and direction of their linear relationship. A result close to 1 indicates a 
# strong positive correlation (as foot length increases, width also increases), while a 
# result near -1 suggests a strong negative correlation (as length increases, width 
# decreases). A value around 0 implies no significant linear relationship between the two 
# variables.
```

```{r}
# Quantitative Y | Multiple X  - length and width and sex
lm(length ~ width + sex, data = KidsFeet) %>%
  pander()

# NOTE: lm() is a function used for linear regression modeling. It is short for 
# "linear model" and helps you fit a linear relationship between a dependent 
# variable and one or more independent variables.
```

```{r}
# Binomial Y | Quantitative X - sex and length - opposite x and y 
glm(sex ~ length, data = KidsFeet, family = binomial) %>%
  pander()

# NOTE: The glm() function in R is used for Generalized Linear Models (GLMs), 
# which extend linear regression (lm()) to support non-normal response 
# distributions (e.g., binary, count data).
```

```{r}
# Binomial Y | Multiple X - Don't worry about it
```

```{r}
# Categorical Y | Categorical X - biggerfoot and domhand
table(KidsFeet$biggerfoot, KidsFeet$domhand) %>%
  pander()
```

### B - Summary Statistics

```{r}
# group_by() - categorical
KidsFeet %>% 
  group_by(sex) %>% 
  summarise(mean_length = mean(length))  %>%
    pander()
```

### C - Visualization

```{r}
# Histogram - quantitative
hist(KidsFeet$length, main="Histogram of Kids Feet Length", xlab="Length")
```

```{r}
# Boxplot - quantitative
boxplot(KidsFeet$length, main="Boxplot of Kids Feet Length", xlab="Length")
```

```{r}
# Dot plot - quantitative
stripchart(KidsFeet$length, method = "jitter", pch = 19, col = "blue", main = "Dot Plot of Kids Feet Length")
```

```{r}
# Scatterplot - quantitative
plot(KidsFeet$width, KidsFeet$length, main="Scatterplot of Length vs Width", xlab="Width", ylab="Length")
```

```{r}
# Bar plot - categorical
barplot(table(KidsFeet$sex), main="Barplot of Gender Count", col=c("blue","pink"))
```

### D - Answering Specific Questions

```{r}
# How many boys and how many girls are in the KidsFeet dataset?
table(KidsFeet$sex)  %>%
  pander()
```

```{r}
barplot(table(KidsFeet$sex), col=c("blue", "pink"), main="Count of Boys and Girls")
```

```{r}
# What is the average length of feet in the KidsFeet dataset?
favstats(KidsFeet$length) %>% pander()
```

```{r}
boxplot(KidsFeet$length, main="Length of Kids Feet")
```

```{r}
# Do boys or girls have longer feet, on average?
favstats(length~sex, data=KidsFeet) %>% 
  pander()
```

```{r}
boxplot(length~sex, data=KidsFeet, main="Comparing Length of Feet Across Gender", 
        xlab="Gender", ylab="Length of Foot", col=c("blue","pink"))
```

```{r}
# Are there certain months of the year associated with longer feet?
favstats(length~birthmonth, data=KidsFeet) %>% 
  pander()
```

```{r}
boxplot(length~birthmonth, data=KidsFeet, col="navy",
        xlab = "Numerical Birth Month", ylab="Feet Length")
```

```{r}
# Is there a relationship between foot length and width?
cor(KidsFeet$length, KidsFeet$width)  %>%
  pander()
```

```{r}
plot(length~width, data=KidsFeet, main="Relationship Between Length and Width of Kids Feet", 
     xlab="Width of Foot", ylab = "Length of Foot")
```

```{r}
# Is one gender more likely to be born in certain seasons?
Kids3 <- KidsFeet %>% 
  mutate(
    season = case_when(
      birthmonth %in% c(12,1,2) ~ "Winter",
      birthmonth %in% c(3,4,5) ~ "Spring",
      birthmonth %in% c(6,7,8) ~ "Summer",
      birthmonth %in% c(9,10,11) ~ "Fall"
    )
  )  
```

```{r}
pander(table(Kids3$season, KidsFeet$sex))
```

```{r}
barplot(table(Kids3$sex, Kids3$season), beside = TRUE,
        col = c("blue","pink"), legend.text=TRUE, 
        xlab="Season", ylab="Frequency", main="Count of Gender by Season")
```

---

# Week 4 Day 1

```{r}
library(mosaic)
library(pander)
library(tidyverse)
library(car)
data(KidsFeet)
```

## Parametric Distributions

The four main **parametric distributions** used in statistical tests:

1. **Normal distribution**
2. **t-distribution**
3. **Chi-square distribution**
4. **F-distribution**

These distributions are used in hypothesis testing and confidence interval estimation in STAT 221.

## Parametric vs. Non-Parametric Methods

- **Parametric methods** assume that data follows a specific distribution (e.g., normal distribution).
- **Non-parametric methods** do not require a specific distribution, making them more flexible.
- **When to use non-parametric tests:**  
  - When the assumptions for parametric tests (e.g., normality) **are not met**.  
  - When working with **small sample sizes** or **ordinal data**.  
- **Non-parametric tests** can sometimes be **more powerful** than parametric tests when assumptions are violated.

## Example of a t-Test

```{r}
t.test(KidsFeet$length, mu = 25.1, alternative = "two.sided", conf.level = 0.95) %>% pander()
```

### Hypotheses:

- **Null Hypothesis (H₀):** μ = 25.1  
- **Alternative Hypothesis (Hₐ):** μ ≠ 25.1  
- **Level of significance:** 0.05

If the p-value is greater than alpha (0.05), we fail to reject H₀. Otherwise, we reject H₀.

## Example of a Paired t-Test

```{r}
KidsFeet3 <- KidsFeet %>% 
  mutate(width3 = 3 * width, difference = length - width3)

t.test(KidsFeet3$length, KidsFeet3$width3, mu = 0, paired = TRUE, 
       alternative = "two.sided", conf.level = 0.95) %>% pander()
```

### Example of an Independent Samples t-Test

```{r}
t.test(length ~ sex, data = KidsFeet, alternative = "two.sided", conf.level = 0.95) %>% pander()
```

## Checking Assumptions

### Normality Assumption for One-Sample t-Test
```{r}
qqPlot(KidsFeet$length)
```

### Normality Assumption for Paired t-Test
```{r}
qqPlot(KidsFeet3$difference)
```

### Normality Assumption for Independent Samples t-Test
```{r}
qqPlot(KidsFeet$length)
```

## Graphics

### Boxplot for One-Sample t-Test
```{r}
boxplot(KidsFeet$length)
```

```{r}
ggplot(data = KidsFeet, aes(x = length)) + 
  geom_boxplot(fill = "skyblue")
```

### Boxplot for Paired t-Test
```{r}
boxplot(KidsFeet3$difference)
```

```{r}
ggplot(data = KidsFeet3, aes(x = difference)) + 
  geom_boxplot(fill = "skyblue")
```

### Boxplot for Independent Samples t-Test
```{r}
boxplot(length ~ sex, data = KidsFeet)
```

```{r}
ggplot(data = KidsFeet, aes(y = length, x = sex)) +
  geom_boxplot(fill = c("skyblue", "pink"))
```

## Numerical Summaries

```{r}
pander(favstats(~length, data = KidsFeet))
```

```{r}
pander(favstats(~difference, data = KidsFeet3))
```

```{r}
pander(favstats(length ~ sex, data = KidsFeet))
```

## Writing Hypotheses in LaTeX

$$
H_0: \mu = 10 \\
$$

$$
H_a: \mu \neq 10
$$

---

# Week 6 Day 1

```{r}
library(pander)
library(mosaic)
library(tidyverse)
library(lattice)
data(airquality)
data(chickwts)
data(warpbreaks)
```

## ANOVA Analysis

### Tasks
1. Find the ANOVA using Statistics Notebook.
2. Compare the difference between t-test and ANOVA using the `index.html` file.
3. Go through the Overview, Explanation, and Instructions in the Textbook.

## Defining Factor and Levels in `airquality`
- The `Month` variable in the `airquality` dataset is a factor with levels: 5, 6, 7, 8, and 9.

## Two-Way ANOVA Preview
- We will cover **two-way ANOVA** next week.

## Numerical and Graphical Summary - `airquality`

```{r}
boxplot(Wind ~ Month, data = airquality)
ggplot(data = airquality, aes(x = as.factor(Month), y = Wind)) +
  geom_boxplot(fill = c("blue", "red", "yellow", "green", "purple"))
pander(favstats(Wind ~ Month, data = airquality))
```

## One-Way ANOVA - `airquality`

```{r}
airq.aov <- aov(Wind ~ as.factor(Month), data = airquality)
pander(summary(airq.aov))
```

## Checking Assumptions

```{r}
par(mfrow = c(1, 2))
plot(airq.aov, which = 1:2)
par(mfrow = c(1, 1))
```

## One-Way ANOVA - `chickwts`

### Hypotheses
$$ H_0: \mu_1 = \mu_2 = \mu_3 = \mu_4 = \mu_5 = \mu_6 $$
$$ H_a: \text{at least one } \mu \text{ is different} $$

### Numerical and Graphical Summary

```{r}
boxplot(weight ~ feed, data = chickwts)
ggplot(data = chickwts, aes(y = weight, x = feed)) +
  geom_boxplot(fill = c("blue", "white", "green", "yellow", "orange", "brown"))

xyplot(weight ~ feed, data = chickwts,
       main = "Effect of Feed Type on Chicken Growth",
       ylab = "Adult Weight of Chickens (g)",
       xlab = "Type of Feed (Blue line shows mean weights per type)",
       type = c("p", "a"))

pander(favstats(weight ~ feed, data = chickwts)[, c("feed", "mean", "sd", "n")])
```

## One-Way ANOVA - `chickwts`

```{r}
chickwt.aov <- aov(weight ~ feed, data = chickwts)
pander(summary(chickwt.aov))
```

## Checking Assumptions

```{r}
par(mfrow = c(1, 2))
plot(chickwt.aov, which = 1:2)
```

## Two-Way ANOVA - `warpbreaks`

### Hypotheses
$$ H_0: \mu_1 = \mu_2 = \mu_3 = \mu \text{ for tension} $$
$$ H_a: \text{at least one } \mu \text{ is different for tension} $$
$$ H_0: \mu_1 = \mu_2 = \mu \text{ for wool} $$
$$ H_a: \text{at least one } \mu \text{ is different for wool} $$
$$ H_0: \text{ The effect of tension is the same for all types of wool} $$
$$ H_a: \text{ The effect of tension is not the same for all types of wool} $$

## Numerical Summaries - `warpbreaks`

```{r}
warpbreaks %>% 
  group_by(tension) %>% 
  summarise(ave = mean(breaks), sd = sd(breaks), SampleSize = n()) %>% pander()

warpbreaks %>% 
  group_by(wool) %>% 
  summarise(ave = mean(breaks), sd = sd(breaks), SampleSize = n()) %>% pander()

warpbreaks %>% 
  group_by(wool, tension) %>% 
  summarise(ave = mean(breaks), sd = sd(breaks), SampleSize = n()) %>% pander()
```

## Graphical Summaries - `warpbreaks`

```{r}
xyplot(breaks ~ wool, data = warpbreaks, type = c("p", "a"),
       main = "Type of Wool", col = 'blue',
       xlab = "Type of Wool", ylab = "Number of Warps that Broke")

xyplot(breaks ~ tension, data = warpbreaks, type = c("p", "a"),
       main = "Type of Tension", col = 'blue',
       xlab = "Type of Tension", ylab = "Number of Warps that Broke")

xyplot(breaks ~ tension, data = warpbreaks, groups = wool, type = c("p", "a"),
       main = "Significance of Interaction",
       auto.key = list(corner = c(1, 1)))
```

## Inferential Statistics - `warpbreaks`

```{r}
warp.aov <- aov(breaks ~ wool + tension + wool:tension, data = warpbreaks)
pander(summary(warp.aov))

par(mfrow = c(1, 2))
plot(warp.aov, which = 1:2, pch = 16)

